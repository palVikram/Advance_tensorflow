{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/palVikram/Advance_tensorflow/blob/main/sentence_similarity_bert_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAQ-FhWdRTEu",
        "outputId": "9867df57-dea4-43ef-ce8f-bb656d446977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.7/dist-packages (1.9.3)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.11.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 319, in run\n",
            "    reqs, check_supported_wheels=not options.target_dir\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 128, in resolve\n",
            "    requirements, max_rounds=try_to_avoid_resolution_too_deep\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 473, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 367, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 213, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_criteria_to_update(candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 203, in _get_criteria_to_update\n",
            "    name, crit = self._merge_into_criterion(r, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 172, in _merge_into_criterion\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/resolvelib/structs.py\", line 139, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 129, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 30, in _iter_built\n",
            "    for version, func in infos:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 272, in iter_index_candidate_infos\n",
            "    hashes=hashes,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 879, in find_best_candidate\n",
            "    candidates = self.find_all_candidates(project_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 824, in find_all_candidates\n",
            "    page_candidates = list(page_candidates_it)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/sources.py\", line 134, in page_candidates\n",
            "    yield from self._candidates_from_page(self._link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 792, in process_project_url\n",
            "    links=page_links,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 772, in evaluate_links\n",
            "    candidate = self.get_install_candidate(link_evaluator, link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 753, in get_install_candidate\n",
            "    is_candidate, result = link_evaluator.evaluate_link(link)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/index/package_finder.py\", line 186, in evaluate_link\n",
            "    if not wheel.supported(supported_tags):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/models/wheel.py\", line 95, in supported\n",
            "    return not self.file_tags.isdisjoint(tags)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_vendor/packaging/tags.py\", line 127, in __hash__\n",
            "    def __hash__(self):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1619, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1424, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1630, in isEnabledFor\n",
            "    _releaseLock()\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 226, in _releaseLock\n",
            "    _lock.release()\n",
            "KeyboardInterrupt\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.3.0\n",
        "!pip install tensorflow transformers tf2onnx onnxruntime\n",
        "!pip install transformers\n",
        "!pip install numpy==1.19.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-Gk6K1M6ZGW",
        "outputId": "3248d959-7b5c-4054-b55c-818bc54baf2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(Reading database ... 155302 files and directories currently installed.)\n",
            "Preparing to unpack nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb ...\n",
            "Unpacking nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) over (1.0.0-1) ...\n",
            "Setting up nvidia-machine-learning-repo-ubuntu1804 (1.0.0-1) ...\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libnvinfer5 is already the newest version (5.1.5-1+cuda10.1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "--2022-05-08 23:33:56--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2926 (2.9K) [application/x-deb]\n",
            "Saving to: ‘nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb.1’\n",
            "\n",
            "     0K ..                                                    100% 76.0M=0s\n",
            "\n",
            "2022-05-08 23:33:56 (76.0 MB/s) - ‘nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb.1’ saved [2926/2926]\n",
            "\n",
            "--2022-05-08 23:33:56--  https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nv-tensorrt-repo-ubuntu1804-cuda11.3-trt8.0.1.6-ga-20210626_1-1_amd64.deb\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2022-05-08 23:33:56 ERROR 404: Not Found.\n",
            "\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n",
            "W: Target Packages (Packages) is configured multiple times in /etc/apt/sources.list.d/nvidia-machine-learning.list:1 and /etc/apt/sources.list.d/nvidia-ml.list:1\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "\n",
        "wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nv-tensorrt-repo-ubuntu1804-cuda11.3-trt8.0.1.6-ga-20210626_1-1_amd64.deb\n",
        "\n",
        "dpkg -i nvidia-machine-learning-repo-*.deb\n",
        "apt-get update\n",
        "\n",
        "sudo apt-get install libnvinfer5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OZciNG0EiFJ",
        "outputId": "39cd1952-76ab-4e36-bc13-00f6d4849ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.3.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "gpu = gpus[0]\n",
        "\n",
        "tf.config.experimental.set_memory_growth(gpu, True)\n",
        "print(\"Tensorflow version: \", tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3Ty2NzpKB9O"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNzaWuV9btSR",
        "outputId": "fd8e866d-ab1f-42da-eba0-4df7bb47f9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 11.1M  100 11.1M    0     0  75.0M      0 --:--:-- --:--:-- --:--:-- 75.0M\n",
            "SNLI_Corpus/\n",
            "SNLI_Corpus/snli_1.0_dev.csv\n",
            "SNLI_Corpus/snli_1.0_train.csv\n",
            "SNLI_Corpus/snli_1.0_test.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "!curl -LO https://raw.githubusercontent.com/MohamadMerchant/SNLI/master/data.tar.gz\n",
        "!tar -xvzf data.tar.gz\n",
        "# There are more than 550k samples in total; we will use 100k for this example.\n",
        "train_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_train.csv\", nrows=5000)\n",
        "valid_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_dev.csv\")\n",
        "test_df = pd.read_csv(\"SNLI_Corpus/snli_1.0_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r4LCPFOCb3Rs",
        "outputId": "25795ae7-c460-46b5-aff4-049a628d1249"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-205bf751-5aa0-4f15-9aeb-756c7566a81f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>similarity</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is training his horse for a competition.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>contradiction</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>entailment</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>They are smiling at their parents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entailment</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>There are children present</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-205bf751-5aa0-4f15-9aeb-756c7566a81f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-205bf751-5aa0-4f15-9aeb-756c7566a81f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-205bf751-5aa0-4f15-9aeb-756c7566a81f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      similarity                                          sentence1  \\\n",
              "0        neutral  A person on a horse jumps over a broken down a...   \n",
              "1  contradiction  A person on a horse jumps over a broken down a...   \n",
              "2     entailment  A person on a horse jumps over a broken down a...   \n",
              "3        neutral              Children smiling and waving at camera   \n",
              "4     entailment              Children smiling and waving at camera   \n",
              "\n",
              "                                           sentence2  \n",
              "0  A person is training his horse for a competition.  \n",
              "1      A person is at a diner, ordering an omelette.  \n",
              "2                  A person is outdoors, on a horse.  \n",
              "3                  They are smiling at their parents  \n",
              "4                         There are children present  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InigSROmFrQI"
      },
      "outputs": [],
      "source": [
        "train_df['is_duplicate']=1\n",
        "train_df['is_duplicate'][train_df['similarity']=='entailment']=1\n",
        "train_df['is_duplicate'][train_df['similarity']=='contradiction']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfkKynJzHIf8"
      },
      "outputs": [],
      "source": [
        "train_df=train_df[(train_df['similarity']=='entailment') | (train_df['similarity']=='contradiction')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9zmplY9H6lR"
      },
      "outputs": [],
      "source": [
        "train_df['question1']=train_df['sentence1']\n",
        "train_df['question2']=train_df['sentence2']\n",
        "\n",
        "train_df.drop(['similarity','sentence1','sentence2'], axis=1, inplace=True)\n",
        "train_df=train_df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPuzcSpaLGFn"
      },
      "outputs": [],
      "source": [
        "train_df.drop('index',axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Qj25mk6Lhvh",
        "outputId": "12e3ae5c-46b3-4b74-d4b6-4ed70a09cf7b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8bb37d7c-bb8b-4b52-bee7-caeebb56a69b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is at a diner, ordering an omelette.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A person on a horse jumps over a broken down a...</td>\n",
              "      <td>A person is outdoors, on a horse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>There are children present</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Children smiling and waving at camera</td>\n",
              "      <td>The kids are frowning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
              "      <td>The boy skates down the sidewalk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb37d7c-bb8b-4b52-bee7-caeebb56a69b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bb37d7c-bb8b-4b52-bee7-caeebb56a69b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bb37d7c-bb8b-4b52-bee7-caeebb56a69b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   is_duplicate                                          question1  \\\n",
              "0             0  A person on a horse jumps over a broken down a...   \n",
              "1             1  A person on a horse jumps over a broken down a...   \n",
              "2             1              Children smiling and waving at camera   \n",
              "3             0              Children smiling and waving at camera   \n",
              "4             0  A boy is jumping on skateboard in the middle o...   \n",
              "\n",
              "                                       question2  \n",
              "0  A person is at a diner, ordering an omelette.  \n",
              "1              A person is outdoors, on a horse.  \n",
              "2                     There are children present  \n",
              "3                          The kids are frowning  \n",
              "4              The boy skates down the sidewalk.  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['my name is vikram']*10"
      ],
      "metadata": {
        "id": "scvruXMLrcZV",
        "outputId": "d211844f-c2f8-4c38-8e26-00b274411523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram',\n",
              " 'my name is vikram']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKpGUCCrIDJj"
      },
      "outputs": [],
      "source": [
        "valid_df['is_duplicate']=1\n",
        "valid_df['is_duplicate'][valid_df['similarity']=='entailment']=1\n",
        "valid_df['is_duplicate'][valid_df['similarity']=='contradiction']=0\n",
        "\n",
        "valid_df=valid_df[(valid_df['similarity']=='entailment') | (valid_df['similarity']=='contradiction')]\n",
        "\n",
        "test_df['is_duplicate']=1\n",
        "test_df['is_duplicate'][test_df['similarity']=='entailment']=1\n",
        "test_df['is_duplicate'][test_df['similarity']=='contradiction']=0\n",
        "\n",
        "test_df=test_df[(test_df['similarity']=='entailment') | (test_df['similarity']=='contradiction')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cjzBoJKImTX"
      },
      "outputs": [],
      "source": [
        "valid_df['question1']=valid_df['sentence1']\n",
        "valid_df['question2']=valid_df['sentence2']\n",
        "\n",
        "valid_df.drop(['similarity','sentence1','sentence2'], axis=1, inplace=True)\n",
        "\n",
        "valid_df=valid_df.reset_index()\n",
        "\n",
        "valid_df.drop('index',axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zklL8u1bImaZ"
      },
      "outputs": [],
      "source": [
        "test_df['question1']=test_df['sentence1']\n",
        "test_df['question2']=test_df['sentence2']\n",
        "\n",
        "test_df.drop(['similarity','sentence1','sentence2'], axis=1, inplace=True)\n",
        "\n",
        "test_df=test_df.reset_index()\n",
        "\n",
        "test_df.drop('index',axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-slE1U-ZASl"
      },
      "outputs": [],
      "source": [
        "with open('paraphrased_sentences.txt') as f:\n",
        "    paraphrased_data = f.read().splitlines()\n",
        "\n",
        "paraphrased_data=[data for data in paraphrased_data if len(data)>0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvJh6_jUT-K9",
        "outputId": "c93389a4-5b15-4957-e421-eb3a3a692b99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "471"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('training_data.txt') as f:\n",
        "    cleaned_data = f.read().splitlines()\n",
        "\n",
        "cleaned=[]\n",
        "for data in cleaned_data:\n",
        "      if '(' in data or ')' in data:\n",
        "        data1=(data[:data.index('(')]+data[data.index(')')+1:]).strip()\n",
        "        data1=data1.replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "        if '(' in data1 or ')' in data1:\n",
        "          data1=(data1[:data1.index('(')]+data1[data1.index(')')+1:]).strip()\n",
        "          data1=data1.replace(\"[\",\"\").replace(\"]\",\"\")\n",
        "        cleaned.append(data1)\n",
        "      else: \n",
        "        data=data.replace(\"[\",\"\").replace(\"]\",\"\").strip()\n",
        "        cleaned.append(data)\n",
        "len(cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Og06qi_7cLC"
      },
      "outputs": [],
      "source": [
        "left_sentence=[]\n",
        "right_sentence=[]\n",
        "\n",
        "for left, right in zip(cleaned, paraphrased_data):\n",
        "  if len(left)>1 and len(right)>1:\n",
        "    left_sentence.append(left)\n",
        "    right_sentence.append(right)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Pphw91O6m9eI",
        "outputId": "5c0e9565-6717-4216-d384-3b3eb587a9b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-26ff9571-1177-492a-9819-b50cd4c3c97f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can you give me news about finance</td>\n",
              "      <td>Can you provide me with financial information?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me the news</td>\n",
              "      <td>Could you please inform me of the latest devel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>give me today's  headlines</td>\n",
              "      <td>Please send me today's news.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>give me today's  news</td>\n",
              "      <td>Please provide me with today's news.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>play the news</td>\n",
              "      <td>turn on the news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>what are npr financial channels</td>\n",
              "      <td>what content do you have</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>what are shows I could watch</td>\n",
              "      <td>what else can you do</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>what are the top programs</td>\n",
              "      <td>what is available for listening</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>what are the top talk shows</td>\n",
              "      <td>what shows can you play</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>what can i ask you to do</td>\n",
              "      <td>what stations do you have</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>466 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26ff9571-1177-492a-9819-b50cd4c3c97f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26ff9571-1177-492a-9819-b50cd4c3c97f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26ff9571-1177-492a-9819-b50cd4c3c97f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                              question1  \\\n",
              "0    can you give me news about finance   \n",
              "1              can you tell me the news   \n",
              "2            give me today's  headlines   \n",
              "3                 give me today's  news   \n",
              "4                         play the news   \n",
              "..                                  ...   \n",
              "461     what are npr financial channels   \n",
              "462        what are shows I could watch   \n",
              "463           what are the top programs   \n",
              "464         what are the top talk shows   \n",
              "465            what can i ask you to do   \n",
              "\n",
              "                                             question2  is_duplicate  \n",
              "0       Can you provide me with financial information?             1  \n",
              "1    Could you please inform me of the latest devel...             1  \n",
              "2                         Please send me today's news.             1  \n",
              "3                 Please provide me with today's news.             1  \n",
              "4                                     turn on the news             1  \n",
              "..                                                 ...           ...  \n",
              "461                           what content do you have             1  \n",
              "462                               what else can you do             1  \n",
              "463                    what is available for listening             1  \n",
              "464                            what shows can you play             1  \n",
              "465                          what stations do you have             1  \n",
              "\n",
              "[466 rows x 3 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "left_sentence=cleaned\n",
        "right_sentence=paraphrased_data\n",
        "len(left_sentence),len(right_sentence)\n",
        "\n",
        "df_data=pd.DataFrame(list(zip(left_sentence,right_sentence)), columns=[\"question1\", \"question2\"])\n",
        "\n",
        "df_data[\"is_duplicate\"]=1\n",
        "df_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9e2gPr2SqMXN",
        "outputId": "b18e2edb-3b39-45b2-9fd4-a7e921ebc8b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8bb9d5a9-ccb5-477e-9a34-71e79c1c6c94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>can you give me news about finance</td>\n",
              "      <td>Can you provide me with financial information?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>can you tell me the news</td>\n",
              "      <td>Could you please inform me of the latest devel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>give me today's  headlines</td>\n",
              "      <td>Please send me today's news.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>give me today's  news</td>\n",
              "      <td>Please provide me with today's news.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>play the news</td>\n",
              "      <td>turn on the news</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3799</th>\n",
              "      <td>3333</td>\n",
              "      <td>A man standing on a motorcycle doing a stunt</td>\n",
              "      <td>a man crashes a car into a pole</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3800</th>\n",
              "      <td>3334</td>\n",
              "      <td>Motorcycle daredevil on reared motorcycle.</td>\n",
              "      <td>Motorcyle crashes into a pile of cars.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3801</th>\n",
              "      <td>3335</td>\n",
              "      <td>Motorcycle daredevil on reared motorcycle.</td>\n",
              "      <td>Motorcylist rides his bike.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3802</th>\n",
              "      <td>3336</td>\n",
              "      <td>Someone riding sideways on a motorcycle.</td>\n",
              "      <td>The rider is straddling the motorcycle.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3803</th>\n",
              "      <td>3337</td>\n",
              "      <td>Someone riding sideways on a motorcycle.</td>\n",
              "      <td>The person is laying in his bedroom.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3804 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bb9d5a9-ccb5-477e-9a34-71e79c1c6c94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8bb9d5a9-ccb5-477e-9a34-71e79c1c6c94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8bb9d5a9-ccb5-477e-9a34-71e79c1c6c94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      index                                     question1  \\\n",
              "0         0            can you give me news about finance   \n",
              "1         1                      can you tell me the news   \n",
              "2         2                    give me today's  headlines   \n",
              "3         3                         give me today's  news   \n",
              "4         4                                 play the news   \n",
              "...     ...                                           ...   \n",
              "3799   3333  A man standing on a motorcycle doing a stunt   \n",
              "3800   3334    Motorcycle daredevil on reared motorcycle.   \n",
              "3801   3335    Motorcycle daredevil on reared motorcycle.   \n",
              "3802   3336      Someone riding sideways on a motorcycle.   \n",
              "3803   3337      Someone riding sideways on a motorcycle.   \n",
              "\n",
              "                                              question2  is_duplicate  \n",
              "0        Can you provide me with financial information?             1  \n",
              "1     Could you please inform me of the latest devel...             1  \n",
              "2                          Please send me today's news.             1  \n",
              "3                  Please provide me with today's news.             1  \n",
              "4                                      turn on the news             1  \n",
              "...                                                 ...           ...  \n",
              "3799                    a man crashes a car into a pole             0  \n",
              "3800             Motorcyle crashes into a pile of cars.             0  \n",
              "3801                        Motorcylist rides his bike.             1  \n",
              "3802            The rider is straddling the motorcycle.             0  \n",
              "3803               The person is laying in his bedroom.             0  \n",
              "\n",
              "[3804 rows x 4 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "###df_data[\"label\"]=np.where(df_data[\"label\"].index<465, df_data[\"label\"], 0)\n",
        "\n",
        "df_merge=pd.concat([df_data,train_df], axis=0).reset_index()\n",
        "\n",
        "df_merge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bon-Sczq4Aj"
      },
      "outputs": [],
      "source": [
        "df_merge.drop('index',axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeGrdnDj8QLq",
        "outputId": "14dd7a81-e7c0-4868-afb9-4f2e166aa4a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "question1       0\n",
              "question2       0\n",
              "is_duplicate    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merge=df_merge.dropna()\n",
        "df_merge.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uezc4XMBRPAt"
      },
      "outputs": [],
      "source": [
        "#df_merge['question1']=df_merge['question1'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpw2uivGKDli",
        "outputId": "6d81ca02-a4fa-4cab-ce2b-9d6bb43c0239"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    2137\n",
              "0    1667\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merge['is_duplicate'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41X2p1NZUp4p",
        "outputId": "8335f413-a61c-4577-c1c3-3e41f9864110"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3774    A man hovers over a woman seated at an art gal...\n",
              "3775                            Racedog has the number 8.\n",
              "3776                            Racedog has the number 8.\n",
              "3777        A dog, wearing a number 8, running in a race.\n",
              "3778        A dog, wearing a number 8, running in a race.\n",
              "3779    A greyhound runs in a race, bee striped jacket...\n",
              "3780    A greyhound runs in a race, bee striped jacket...\n",
              "3781    A greyhound dog wearing a yellow and black shi...\n",
              "3782    A greyhound dog wearing a yellow and black shi...\n",
              "3783    A greyhound dog wearing a yellow and black shi...\n",
              "3784    A greyhound dog wearing a yellow and black shi...\n",
              "3785    A greyhound dog wearing a yellow and black shi...\n",
              "3786    A greyhound dog wearing a yellow and black shi...\n",
              "3787    A greyhound dog wearing a yellow and black shi...\n",
              "3788    A greyhound dog wearing a yellow and black shi...\n",
              "3789    A greyhound dog wearing a yellow and black shi...\n",
              "3790    A greyhound dog wearing a yellow and black shi...\n",
              "3791    Gray dog with muzzle and with the# 8 yellow st...\n",
              "3792    Gray dog with muzzle and with the# 8 yellow st...\n",
              "3793    A man wearing white clothes with a blue backpa...\n",
              "3794          A man dressed in red is at the marketplace.\n",
              "3795          A man dressed in red is at the marketplace.\n",
              "3796    A person performing a wheelie trick on a motor...\n",
              "3797    A person performing a wheelie trick on a motor...\n",
              "3798         A man standing on a motorcycle doing a stunt\n",
              "3799         A man standing on a motorcycle doing a stunt\n",
              "3800           Motorcycle daredevil on reared motorcycle.\n",
              "3801           Motorcycle daredevil on reared motorcycle.\n",
              "3802             Someone riding sideways on a motorcycle.\n",
              "3803             Someone riding sideways on a motorcycle.\n",
              "Name: question1, dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merge['question1'].tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJeKvLVeSZeb"
      },
      "outputs": [],
      "source": [
        "#df_merge['question2']=df_merge['question2'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kUrFCKhUD5c"
      },
      "outputs": [],
      "source": [
        "left_train_x=df_merge['question1'].tolist()\n",
        "right_train_x=df_merge['question2'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7gWPPepSp5Z"
      },
      "outputs": [],
      "source": [
        "#valid_df['question1']=valid_df['question1'].apply(lambda x: remove_stopwords(x))\n",
        "#valid_df['question2']=valid_df['question2'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c2DYPvsw2S3"
      },
      "outputs": [],
      "source": [
        "#test_df['question1']=test_df['question1'].apply(lambda x: remove_stopwords(x))\n",
        "#test_df['question2']=test_df['question2'].apply(lambda x: remove_stopwords(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzCBcYOBxIDM"
      },
      "outputs": [],
      "source": [
        "question1_list=test_df['question1'].tolist()\n",
        "question2_list=test_df['question2'].tolist()\n",
        "y_list=test_df['is_duplicate'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SqkALEVUG7H"
      },
      "outputs": [],
      "source": [
        "left_test_x=valid_df['question1'].tolist()\n",
        "right_test_x=valid_df['question2'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvV4J_Ym0Pzz"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuvG0a9J-fQS"
      },
      "outputs": [],
      "source": [
        "max_length = 128  # Maximum length of input sentence to the model.\n",
        "batch_size = 16\n",
        "epochs = 2\n",
        "\n",
        "# Labels in our dataset.\n",
        "labels = [\"contradiction\", \"entailment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwUiXjG0EuBT"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(\"huawei-noah/TinyBERT_4L_zh\", do_lower_case=True)\n",
        "#tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\", do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnMOl7GaSwoc",
        "outputId": "b33f7ee7-ca95-4114-c22c-06f380eed59a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvI7NOKL9uEF"
      },
      "outputs": [],
      "source": [
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentence_pairs,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentence_pairs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentence_pairs = self.sentence_pairs[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = tokenizer.batch_encode_plus(\n",
        "            sentence_pairs.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71Cnk3fcGaVo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x-1Lkdm913F",
        "outputId": "6f664f05-831e-44cd-df76-683bab8ee56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.weight', 'fit_dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'fit_dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7fd8d688f4d0>\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 11419320    input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 128)     193024      tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            257         dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 11,612,601\n",
            "Trainable params: 193,281\n",
            "Non-trainable params: 11,419,320\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model under a distribution strategy scope.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    # Encoded token ids from BERT tokenizer.\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "    )\n",
        "    # Attention masks indicates to the model which tokens should be attended to.\n",
        "    attention_masks = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "    )\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "    )\n",
        "    # Loading pretrained BERT model.\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"huawei-noah/TinyBERT_4L_zh\",from_pt=True)\n",
        "    #bert_model = transformers.GPT2Model.from_pretrained(\"gpt2\")\n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    bert_output = bert_model(\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "    )\n",
        "    sequence_output = bert_output.last_hidden_state\n",
        "    #pooled_output = bert_output.pooler_output\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(\n",
        "        \n",
        "        tf.keras.layers.LSTM(64, return_sequences=True)\n",
        "    )(sequence_output)\n",
        "    \n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
        "    output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(dropout)\n",
        "    model = tf.keras.models.Model(\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"acc\"],\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"Strategy: {strategy}\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1WRNHVX-Ova",
        "outputId": "52404492-8098-462e-f07f-4a20ae2444f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    1671\n",
              "0    1667\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['is_duplicate'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ84lzwY949s"
      },
      "outputs": [],
      "source": [
        "train_data = BertSemanticDataGenerator(\n",
        "    train_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    train_df['is_duplicate'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "valid_data = BertSemanticDataGenerator(\n",
        "    valid_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    valid_df['is_duplicate'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxmNVaCW98OX",
        "outputId": "e2048643-fd88-44b7-e62d-9639666cfd10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "176/208 [========================>.....] - ETA: 1s - loss: 0.7161 - acc: 0.5273"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "208/208 [==============================] - ETA: 0s - loss: 0.7118 - acc: 0.5337INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "208/208 [==============================] - 19s 93ms/step - loss: 0.7118 - acc: 0.5337 - val_loss: 0.6688 - val_acc: 0.5237\n",
            "Epoch 2/2\n",
            " 79/208 [==========>...................] - ETA: 3s - loss: 0.6693 - acc: 0.5854"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "208/208 [==============================] - ETA: 0s - loss: 0.6562 - acc: 0.6076"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r208/208 [==============================] - 16s 79ms/step - loss: 0.6562 - acc: 0.6076 - val_loss: 0.5960 - val_acc: 0.7386\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JQNAMfSN-AeB",
        "outputId": "ace367cd-437d-4466-e55a-10dc82537b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 11419320    input_ids[0][0]                  \n",
            "                                                                 attention_masks[0][0]            \n",
            "                                                                 token_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 128, 128)     193024      tf_bert_model[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
            "                                                                 global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            257         dropout_13[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 11,612,601\n",
            "Trainable params: 11,612,601\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Unfreeze the bert_model.\n",
        "bert_model.trainable = True\n",
        "# Recompile the model to make the change effective.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"binary_crossentropy\",\n",
        "\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNPTn9qV-BkP"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z095oMmM-DWH",
        "outputId": "50f381d8-b3fd-47c8-a267-1d8990dc6dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 91/412 [=====>........................] - ETA: 46s - loss: 0.1224 - accuracy: 0.9533"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/412 [=====>........................] - ETA: 45s - loss: 0.1254 - accuracy: 0.9531"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "109/412 [======>.......................] - ETA: 43s - loss: 0.1245 - accuracy: 0.9541"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "412/412 [==============================] - 60s 145ms/step - loss: 0.1213 - accuracy: 0.9539\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.12133292853832245, 0.9538834691047668]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = BertSemanticDataGenerator(\n",
        "    test_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
        "    test_df['is_duplicate'],\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "model.evaluate(test_data, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkmQlKCEYezS"
      },
      "outputs": [],
      "source": [
        "def check_similarity(sentence1, sentence2):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = model.predict(test_data[0])[0]\n",
        "    print(proba)\n",
        "    idx = np.argmax(proba)\n",
        "    \n",
        "    proba = f\"{proba[idx]: .2f}%\"\n",
        "    return proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqDgYBXenctZ"
      },
      "outputs": [],
      "source": [
        "cleaned=[clean for clean in cleaned if len(clean)>1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW7GVPC16rM1"
      },
      "outputs": [],
      "source": [
        "input_infer=['play npr news']*len(cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZAL-cSR6emO",
        "outputId": "d8b72c37-2289-451f-9c0b-65fd4cf55194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([0.00250908], dtype=float32),\n",
              " array([0.89061344], dtype=float32),\n",
              " array([0.6832818], dtype=float32),\n",
              " array([0.7680873], dtype=float32),\n",
              " array([0.9351207], dtype=float32),\n",
              " array([0.93466645], dtype=float32),\n",
              " array([0.00244383], dtype=float32),\n",
              " array([0.6777355], dtype=float32),\n",
              " array([0.97911924], dtype=float32),\n",
              " array([0.9587685], dtype=float32),\n",
              " array([0.98704696], dtype=float32),\n",
              " array([0.9587685], dtype=float32),\n",
              " array([0.88675094], dtype=float32),\n",
              " array([0.08993897], dtype=float32),\n",
              " array([0.9178036], dtype=float32),\n",
              " array([0.9821231], dtype=float32),\n",
              " array([0.726428], dtype=float32),\n",
              " array([0.6865537], dtype=float32),\n",
              " array([0.099333], dtype=float32),\n",
              " array([0.82516855], dtype=float32),\n",
              " array([0.88854825], dtype=float32),\n",
              " array([0.4001964], dtype=float32),\n",
              " array([0.81479377], dtype=float32),\n",
              " array([0.8539466], dtype=float32),\n",
              " array([0.9821231], dtype=float32),\n",
              " array([0.81739545], dtype=float32),\n",
              " array([0.05912878], dtype=float32),\n",
              " array([0.03247603], dtype=float32),\n",
              " array([0.17813379], dtype=float32),\n",
              " array([0.73070073], dtype=float32),\n",
              " array([0.5623956], dtype=float32),\n",
              " array([0.9087516], dtype=float32),\n",
              " array([0.9351207], dtype=float32),\n",
              " array([0.84387535], dtype=float32),\n",
              " array([0.94916797], dtype=float32),\n",
              " array([0.4556804], dtype=float32),\n",
              " array([0.68712026], dtype=float32),\n",
              " array([0.76775694], dtype=float32),\n",
              " array([0.6390361], dtype=float32),\n",
              " array([0.52483535], dtype=float32),\n",
              " array([0.78463864], dtype=float32),\n",
              " array([0.8141139], dtype=float32),\n",
              " array([0.28015292], dtype=float32),\n",
              " array([0.80019957], dtype=float32),\n",
              " array([0.6434633], dtype=float32),\n",
              " array([0.5752525], dtype=float32),\n",
              " array([0.71935797], dtype=float32),\n",
              " array([0.04488672], dtype=float32),\n",
              " array([0.5252351], dtype=float32),\n",
              " array([0.854323], dtype=float32),\n",
              " array([0.86679906], dtype=float32),\n",
              " array([0.05896838], dtype=float32),\n",
              " array([0.8997713], dtype=float32),\n",
              " array([0.64281857], dtype=float32),\n",
              " array([0.6675854], dtype=float32),\n",
              " array([0.83857185], dtype=float32),\n",
              " array([0.86679906], dtype=float32),\n",
              " array([0.8567992], dtype=float32),\n",
              " array([0.71935797], dtype=float32),\n",
              " array([0.854323], dtype=float32),\n",
              " array([0.7189336], dtype=float32),\n",
              " array([0.5721027], dtype=float32),\n",
              " array([0.71032894], dtype=float32),\n",
              " array([0.8392374], dtype=float32),\n",
              " array([0.86097634], dtype=float32),\n",
              " array([0.9351207], dtype=float32),\n",
              " array([0.9087516], dtype=float32),\n",
              " array([0.9393333], dtype=float32),\n",
              " array([0.9827183], dtype=float32),\n",
              " array([0.80386454], dtype=float32),\n",
              " array([0.6614133], dtype=float32),\n",
              " array([0.6811692], dtype=float32),\n",
              " array([0.5857254], dtype=float32),\n",
              " array([0.6832818], dtype=float32),\n",
              " array([0.6383356], dtype=float32),\n",
              " array([0.9626039], dtype=float32),\n",
              " array([0.9180149], dtype=float32),\n",
              " array([0.9702232], dtype=float32),\n",
              " array([0.648574], dtype=float32),\n",
              " array([0.03533079], dtype=float32),\n",
              " array([0.5623956], dtype=float32),\n",
              " array([0.75353473], dtype=float32),\n",
              " array([0.61151075], dtype=float32),\n",
              " array([0.8141139], dtype=float32),\n",
              " array([0.64623165], dtype=float32),\n",
              " array([0.7281392], dtype=float32),\n",
              " array([0.7543384], dtype=float32),\n",
              " array([0.5937947], dtype=float32),\n",
              " array([0.5845582], dtype=float32),\n",
              " array([0.71681494], dtype=float32),\n",
              " array([0.47343633], dtype=float32),\n",
              " array([0.0637866], dtype=float32),\n",
              " array([0.77624196], dtype=float32),\n",
              " array([0.61035836], dtype=float32),\n",
              " array([0.55795306], dtype=float32),\n",
              " array([0.61015636], dtype=float32),\n",
              " array([0.60811955], dtype=float32),\n",
              " array([0.5919061], dtype=float32),\n",
              " array([0.600151], dtype=float32),\n",
              " array([0.5506316], dtype=float32),\n",
              " array([0.8365387], dtype=float32),\n",
              " array([0.8858362], dtype=float32),\n",
              " array([0.67114073], dtype=float32),\n",
              " array([0.5252351], dtype=float32),\n",
              " array([0.64281857], dtype=float32),\n",
              " array([0.69913065], dtype=float32),\n",
              " array([0.8356004], dtype=float32),\n",
              " array([0.76054776], dtype=float32),\n",
              " array([0.7653926], dtype=float32),\n",
              " array([0.9811241], dtype=float32),\n",
              " array([0.94479656], dtype=float32),\n",
              " array([0.471585], dtype=float32),\n",
              " array([0.48005083], dtype=float32),\n",
              " array([0.48741108], dtype=float32),\n",
              " array([0.11283001], dtype=float32),\n",
              " array([0.7420172], dtype=float32),\n",
              " array([0.00804555], dtype=float32),\n",
              " array([0.45837784], dtype=float32),\n",
              " array([0.84162724], dtype=float32),\n",
              " array([0.00995139], dtype=float32),\n",
              " array([0.5806957], dtype=float32),\n",
              " array([0.67934614], dtype=float32),\n",
              " array([0.43892953], dtype=float32),\n",
              " array([0.00768705], dtype=float32),\n",
              " array([0.46432713], dtype=float32),\n",
              " array([0.45127985], dtype=float32),\n",
              " array([0.45127985], dtype=float32),\n",
              " array([0.25873747], dtype=float32),\n",
              " array([0.25608608], dtype=float32),\n",
              " array([0.30887008], dtype=float32),\n",
              " array([0.12675], dtype=float32),\n",
              " array([0.06850515], dtype=float32),\n",
              " array([0.22468121], dtype=float32),\n",
              " array([0.25340694], dtype=float32),\n",
              " array([0.07355935], dtype=float32),\n",
              " array([0.6643562], dtype=float32),\n",
              " array([0.5217604], dtype=float32),\n",
              " array([0.55599546], dtype=float32),\n",
              " array([0.15009326], dtype=float32),\n",
              " array([0.00340979], dtype=float32),\n",
              " array([0.69774276], dtype=float32),\n",
              " array([0.5657714], dtype=float32),\n",
              " array([0.7880537], dtype=float32),\n",
              " array([0.27584693], dtype=float32),\n",
              " array([0.561176], dtype=float32),\n",
              " array([0.05527252], dtype=float32),\n",
              " array([0.08220558], dtype=float32),\n",
              " array([0.7096375], dtype=float32),\n",
              " array([0.38351902], dtype=float32),\n",
              " array([0.46866173], dtype=float32),\n",
              " array([0.05701606], dtype=float32),\n",
              " array([0.40232837], dtype=float32),\n",
              " array([0.24246085], dtype=float32),\n",
              " array([0.55456674], dtype=float32),\n",
              " array([0.3697477], dtype=float32),\n",
              " array([0.29757574], dtype=float32),\n",
              " array([0.21417764], dtype=float32),\n",
              " array([0.38067862], dtype=float32),\n",
              " array([0.46798605], dtype=float32),\n",
              " array([0.5398833], dtype=float32),\n",
              " array([0.00411758], dtype=float32),\n",
              " array([0.6017506], dtype=float32),\n",
              " array([0.02646352], dtype=float32),\n",
              " array([0.34655306], dtype=float32),\n",
              " array([0.26213616], dtype=float32),\n",
              " array([0.75839645], dtype=float32),\n",
              " array([0.00430229], dtype=float32),\n",
              " array([0.78410685], dtype=float32),\n",
              " array([0.53782445], dtype=float32),\n",
              " array([0.09008457], dtype=float32),\n",
              " array([0.09008457], dtype=float32),\n",
              " array([0.02330591], dtype=float32),\n",
              " array([0.50196105], dtype=float32),\n",
              " array([0.48305568], dtype=float32),\n",
              " array([0.08000498], dtype=float32),\n",
              " array([0.5134779], dtype=float32),\n",
              " array([0.10675567], dtype=float32),\n",
              " array([0.21363702], dtype=float32),\n",
              " array([0.4391468], dtype=float32),\n",
              " array([0.6590484], dtype=float32),\n",
              " array([0.70672953], dtype=float32),\n",
              " array([0.1764333], dtype=float32),\n",
              " array([0.5398833], dtype=float32),\n",
              " array([0.35032955], dtype=float32),\n",
              " array([0.18734908], dtype=float32),\n",
              " array([0.32548985], dtype=float32),\n",
              " array([0.17333362], dtype=float32),\n",
              " array([0.32548985], dtype=float32),\n",
              " array([0.5111481], dtype=float32),\n",
              " array([0.42113084], dtype=float32),\n",
              " array([0.42113084], dtype=float32),\n",
              " array([0.23313741], dtype=float32),\n",
              " array([0.38454023], dtype=float32),\n",
              " array([0.38454023], dtype=float32),\n",
              " array([0.73330975], dtype=float32),\n",
              " array([0.5000541], dtype=float32),\n",
              " array([0.21999231], dtype=float32),\n",
              " array([0.5697372], dtype=float32),\n",
              " array([0.7232717], dtype=float32),\n",
              " array([0.84970355], dtype=float32),\n",
              " array([0.6931757], dtype=float32),\n",
              " array([0.94479656], dtype=float32),\n",
              " array([0.5837762], dtype=float32),\n",
              " array([0.94479656], dtype=float32),\n",
              " array([0.8444778], dtype=float32),\n",
              " array([0.72502166], dtype=float32),\n",
              " array([0.9359818], dtype=float32),\n",
              " array([0.8277826], dtype=float32),\n",
              " array([0.7678508], dtype=float32),\n",
              " array([0.7691991], dtype=float32),\n",
              " array([0.01255777], dtype=float32),\n",
              " array([0.03397596], dtype=float32),\n",
              " array([0.02622038], dtype=float32),\n",
              " array([0.03667349], dtype=float32),\n",
              " array([0.22895327], dtype=float32),\n",
              " array([0.16456427], dtype=float32),\n",
              " array([0.21043755], dtype=float32),\n",
              " array([0.0564975], dtype=float32),\n",
              " array([0.06500831], dtype=float32),\n",
              " array([0.00188495], dtype=float32),\n",
              " array([0.00787615], dtype=float32),\n",
              " array([0.04121986], dtype=float32),\n",
              " array([0.16829109], dtype=float32),\n",
              " array([0.02027121], dtype=float32),\n",
              " array([0.01845314], dtype=float32),\n",
              " array([0.00395525], dtype=float32),\n",
              " array([0.00709783], dtype=float32),\n",
              " array([0.02787859], dtype=float32),\n",
              " array([0.05317114], dtype=float32),\n",
              " array([0.00106964], dtype=float32),\n",
              " array([0.00060904], dtype=float32),\n",
              " array([0.01777829], dtype=float32),\n",
              " array([0.00138505], dtype=float32),\n",
              " array([0.00219664], dtype=float32),\n",
              " array([0.00166689], dtype=float32),\n",
              " array([0.00934917], dtype=float32),\n",
              " array([0.00224799], dtype=float32),\n",
              " array([0.00217272], dtype=float32),\n",
              " array([0.00811593], dtype=float32),\n",
              " array([0.6618651], dtype=float32),\n",
              " array([0.00700148], dtype=float32),\n",
              " array([0.51675063], dtype=float32),\n",
              " array([0.0055184], dtype=float32),\n",
              " array([0.03151779], dtype=float32),\n",
              " array([0.15324959], dtype=float32),\n",
              " array([0.00642072], dtype=float32),\n",
              " array([0.1746222], dtype=float32),\n",
              " array([0.13653064], dtype=float32),\n",
              " array([0.01120249], dtype=float32),\n",
              " array([0.00826327], dtype=float32),\n",
              " array([0.1220656], dtype=float32),\n",
              " array([0.29193753], dtype=float32),\n",
              " array([0.00426464], dtype=float32),\n",
              " array([0.00679313], dtype=float32),\n",
              " array([0.00906752], dtype=float32),\n",
              " array([0.00621341], dtype=float32),\n",
              " array([0.00126677], dtype=float32),\n",
              " array([0.17908388], dtype=float32),\n",
              " array([0.00516214], dtype=float32),\n",
              " array([0.0417136], dtype=float32),\n",
              " array([0.00178805], dtype=float32),\n",
              " array([0.00100879], dtype=float32),\n",
              " array([0.00171831], dtype=float32),\n",
              " array([0.00780704], dtype=float32),\n",
              " array([0.00208974], dtype=float32),\n",
              " array([0.13500042], dtype=float32),\n",
              " array([0.00120306], dtype=float32),\n",
              " array([0.01121921], dtype=float32),\n",
              " array([0.00022329], dtype=float32),\n",
              " array([0.01212442], dtype=float32),\n",
              " array([0.5567259], dtype=float32),\n",
              " array([0.46950442], dtype=float32),\n",
              " array([0.00124148], dtype=float32),\n",
              " array([0.00278797], dtype=float32),\n",
              " array([0.01845046], dtype=float32),\n",
              " array([0.02061839], dtype=float32),\n",
              " array([0.30915627], dtype=float32),\n",
              " array([0.00151213], dtype=float32),\n",
              " array([0.00161034], dtype=float32),\n",
              " array([0.00124639], dtype=float32),\n",
              " array([0.05447294], dtype=float32),\n",
              " array([0.05953417], dtype=float32),\n",
              " array([0.00072255], dtype=float32),\n",
              " array([0.05274656], dtype=float32),\n",
              " array([0.02109319], dtype=float32),\n",
              " array([0.01023241], dtype=float32),\n",
              " array([0.15156217], dtype=float32),\n",
              " array([0.0012868], dtype=float32),\n",
              " array([0.02046232], dtype=float32),\n",
              " array([0.0107957], dtype=float32),\n",
              " array([0.04420551], dtype=float32),\n",
              " array([0.00091815], dtype=float32),\n",
              " array([0.05557406], dtype=float32),\n",
              " array([0.00289948], dtype=float32),\n",
              " array([0.2572554], dtype=float32),\n",
              " array([0.01405341], dtype=float32),\n",
              " array([0.00208564], dtype=float32),\n",
              " array([0.10258071], dtype=float32),\n",
              " array([0.00100238], dtype=float32),\n",
              " array([0.00080018], dtype=float32),\n",
              " array([0.00264262], dtype=float32),\n",
              " array([0.01661354], dtype=float32),\n",
              " array([0.00737329], dtype=float32),\n",
              " array([0.00176447], dtype=float32),\n",
              " array([0.00809177], dtype=float32),\n",
              " array([0.08315068], dtype=float32),\n",
              " array([0.00572149], dtype=float32),\n",
              " array([0.40599042], dtype=float32),\n",
              " array([0.00102324], dtype=float32),\n",
              " array([0.03530821], dtype=float32),\n",
              " array([0.00451162], dtype=float32),\n",
              " array([0.00053763], dtype=float32),\n",
              " array([0.1682868], dtype=float32),\n",
              " array([0.00276762], dtype=float32),\n",
              " array([0.00821271], dtype=float32),\n",
              " array([0.00842967], dtype=float32),\n",
              " array([0.05500075], dtype=float32),\n",
              " array([0.00955894], dtype=float32),\n",
              " array([0.01319559], dtype=float32),\n",
              " array([0.00501156], dtype=float32),\n",
              " array([0.00120869], dtype=float32),\n",
              " array([0.00466879], dtype=float32),\n",
              " array([0.14931184], dtype=float32),\n",
              " array([0.12729356], dtype=float32),\n",
              " array([0.06154271], dtype=float32),\n",
              " array([0.00404427], dtype=float32),\n",
              " array([0.00238846], dtype=float32),\n",
              " array([0.23976253], dtype=float32),\n",
              " array([0.00277933], dtype=float32),\n",
              " array([0.04965212], dtype=float32),\n",
              " array([0.00567847], dtype=float32),\n",
              " array([0.0419711], dtype=float32),\n",
              " array([0.00208837], dtype=float32),\n",
              " array([0.00385905], dtype=float32),\n",
              " array([0.00100582], dtype=float32),\n",
              " array([0.00219467], dtype=float32),\n",
              " array([0.00201652], dtype=float32),\n",
              " array([0.257101], dtype=float32),\n",
              " array([0.99177355], dtype=float32),\n",
              " array([0.9514065], dtype=float32),\n",
              " array([0.00446198], dtype=float32),\n",
              " array([0.6617915], dtype=float32),\n",
              " array([0.45310527], dtype=float32),\n",
              " array([0.75649005], dtype=float32),\n",
              " array([0.6094754], dtype=float32),\n",
              " array([0.688557], dtype=float32),\n",
              " array([0.67360383], dtype=float32),\n",
              " array([0.51033574], dtype=float32),\n",
              " array([0.60306007], dtype=float32),\n",
              " array([0.6583003], dtype=float32),\n",
              " array([0.15219688], dtype=float32),\n",
              " array([0.3313649], dtype=float32),\n",
              " array([0.31743217], dtype=float32),\n",
              " array([0.477782], dtype=float32),\n",
              " array([0.5011094], dtype=float32),\n",
              " array([0.3598409], dtype=float32),\n",
              " array([0.72938365], dtype=float32),\n",
              " array([0.46446523], dtype=float32),\n",
              " array([0.60804445], dtype=float32),\n",
              " array([0.6692016], dtype=float32),\n",
              " array([0.64688987], dtype=float32),\n",
              " array([0.7138167], dtype=float32),\n",
              " array([0.7138167], dtype=float32),\n",
              " array([0.4375161], dtype=float32),\n",
              " array([0.8925994], dtype=float32),\n",
              " array([0.75028527], dtype=float32),\n",
              " array([0.94733286], dtype=float32),\n",
              " array([0.74759406], dtype=float32),\n",
              " array([0.78009415], dtype=float32),\n",
              " array([0.3996214], dtype=float32),\n",
              " array([0.09311487], dtype=float32),\n",
              " array([0.28998032], dtype=float32),\n",
              " array([0.654514], dtype=float32),\n",
              " array([0.28803772], dtype=float32),\n",
              " array([0.5089443], dtype=float32),\n",
              " array([0.42864454], dtype=float32),\n",
              " array([0.45515966], dtype=float32),\n",
              " array([0.45255786], dtype=float32),\n",
              " array([0.69396013], dtype=float32),\n",
              " array([0.8068342], dtype=float32),\n",
              " array([0.75092417], dtype=float32),\n",
              " array([0.665302], dtype=float32),\n",
              " array([0.33018088], dtype=float32),\n",
              " array([0.05290284], dtype=float32),\n",
              " array([0.0179381], dtype=float32),\n",
              " array([0.11037579], dtype=float32),\n",
              " array([0.06188537], dtype=float32),\n",
              " array([0.00732098], dtype=float32),\n",
              " array([0.03063619], dtype=float32),\n",
              " array([0.7519702], dtype=float32),\n",
              " array([0.88772106], dtype=float32),\n",
              " array([0.4597725], dtype=float32),\n",
              " array([0.04673794], dtype=float32),\n",
              " array([0.06340096], dtype=float32),\n",
              " array([0.18043353], dtype=float32),\n",
              " array([0.10367593], dtype=float32),\n",
              " array([0.3740511], dtype=float32),\n",
              " array([0.01945783], dtype=float32),\n",
              " array([0.17389888], dtype=float32),\n",
              " array([0.05154116], dtype=float32)]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_result=[]\n",
        "encoded_pair=[]\n",
        "for sentence1, sentence2 in zip(input_infer[:400], cleaned[:400]):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "    encoded_pair.append(test_data)\n",
        "\n",
        "for test_data in encoded_pair:\n",
        "    proba = model.predict(test_data[0])[0]  \n",
        "    final_result.append(proba)\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpS0WqfS7oCg"
      },
      "outputs": [],
      "source": [
        "#train_df[[\"question1\", \"question2\"]].values[:450]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WpawLnexIjM"
      },
      "outputs": [],
      "source": [
        "final_result=[]\n",
        "for sentence1, sentence2 in zip(input_infer, cleaned):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "    proba = model.predict(test_data[0])[0]  \n",
        "    final_result.append(proba)\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOyILH7QxE02"
      },
      "outputs": [],
      "source": [
        "final_result=[]\n",
        "for sentence1, sentence2 in zip(input_infer, cleaned):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "    proba = model.predict(test_data[0])[0]  \n",
        "    final_result.append(proba)\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "YFLk84DRcEhG",
        "outputId": "690b9c94-9217-4723-c99a-5085e0bb9c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-gpu 2.3.0 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.21.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sehfn0rrVMqb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import onnxruntime as rt\n",
        "import tensorflow as tf\n",
        "import tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUBzUNOYVNY_"
      },
      "outputs": [],
      "source": [
        "# describe the inputs\n",
        "input_spec = (\n",
        "    tf.TensorSpec((1,max_length,), tf.int32, name=\"input_ids\"),\n",
        "    tf.TensorSpec((1,max_length,), tf.int32, name=\"attention_masks\"),\n",
        "    tf.TensorSpec((1,max_length), tf.int32, name=\"token_type_ids\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEIhSVpnZkRX",
        "outputId": "bceefb94-017e-456d-b084-3d51ef5325be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.9696498], dtype=float32)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence1 = \"play news\"\n",
        "sentence2 = \"play news\"\n",
        "\n",
        "sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "input_dict = BertSemanticDataGenerator(\n",
        "    sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        ")\n",
        "\n",
        "tf_results = model.predict(input_dict[0])[0]\n",
        "tf_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XE4tM-tCVRxj",
        "outputId": "3647e5c8-b5ba-45b3-b828-78f41594f68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf2onnx/tf_loader.py:706: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rnn LSTM__63 following Reverse op isn't the part of bi-rnn.\n"
          ]
        }
      ],
      "source": [
        "# and convert\n",
        "_, _ = tf2onnx.convert.from_keras(model, input_signature=input_spec, opset=13, output_path=\"bert.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9zXGuFYacKX"
      },
      "outputs": [],
      "source": [
        "opt = rt.SessionOptions()\n",
        "sess = rt.InferenceSession(\"bert.onnx\", None)\n",
        "\n",
        "input_ids=sess.get_inputs()[0].name\n",
        "attention_mask=sess.get_inputs()[1].name\n",
        "token_type_ids=sess.get_inputs()[2].name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWX6SM4gDZfi"
      },
      "outputs": [],
      "source": [
        "input_dict_np={input_ids:input_dict[0][0],attention_mask:input_dict[0][1], token_type_ids:input_dict[0][2]}\n",
        "input_dict_np\n",
        "onnx_results = sess.run(None,input_dict_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eYxX-N6roUt"
      },
      "outputs": [],
      "source": [
        "final_result=[]\n",
        "encoded_pair=[]\n",
        "for sentence1, sentence2 in zip(input_infer[:400], cleaned[:400]):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "    encoded_pair.append(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnMyJK-hT1d",
        "outputId": "4402601b-7b54-4d88-cf32-2bfbee01090a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[array([[0.00250906]], dtype=float32)],\n",
              " [array([[0.89061344]], dtype=float32)],\n",
              " [array([[0.68328196]], dtype=float32)],\n",
              " [array([[0.7680876]], dtype=float32)],\n",
              " [array([[0.9351208]], dtype=float32)],\n",
              " [array([[0.93466645]], dtype=float32)],\n",
              " [array([[0.00244379]], dtype=float32)],\n",
              " [array([[0.6777359]], dtype=float32)],\n",
              " [array([[0.9791193]], dtype=float32)],\n",
              " [array([[0.95876855]], dtype=float32)],\n",
              " [array([[0.98704696]], dtype=float32)],\n",
              " [array([[0.95876855]], dtype=float32)],\n",
              " [array([[0.88675094]], dtype=float32)],\n",
              " [array([[0.08993891]], dtype=float32)],\n",
              " [array([[0.91780365]], dtype=float32)],\n",
              " [array([[0.98212314]], dtype=float32)],\n",
              " [array([[0.7264276]], dtype=float32)],\n",
              " [array([[0.6865536]], dtype=float32)],\n",
              " [array([[0.09933332]], dtype=float32)],\n",
              " [array([[0.8251691]], dtype=float32)],\n",
              " [array([[0.888548]], dtype=float32)],\n",
              " [array([[0.40019608]], dtype=float32)],\n",
              " [array([[0.8147938]], dtype=float32)],\n",
              " [array([[0.8539467]], dtype=float32)],\n",
              " [array([[0.98212314]], dtype=float32)],\n",
              " [array([[0.8173946]], dtype=float32)],\n",
              " [array([[0.05912891]], dtype=float32)],\n",
              " [array([[0.03247586]], dtype=float32)],\n",
              " [array([[0.17813382]], dtype=float32)],\n",
              " [array([[0.73070073]], dtype=float32)],\n",
              " [array([[0.5623948]], dtype=float32)],\n",
              " [array([[0.90875185]], dtype=float32)],\n",
              " [array([[0.9351208]], dtype=float32)],\n",
              " [array([[0.8438754]], dtype=float32)],\n",
              " [array([[0.9491681]], dtype=float32)],\n",
              " [array([[0.45568013]], dtype=float32)],\n",
              " [array([[0.6871202]], dtype=float32)],\n",
              " [array([[0.7677566]], dtype=float32)],\n",
              " [array([[0.6390361]], dtype=float32)],\n",
              " [array([[0.52483463]], dtype=float32)],\n",
              " [array([[0.78463894]], dtype=float32)],\n",
              " [array([[0.81411386]], dtype=float32)],\n",
              " [array([[0.28015214]], dtype=float32)],\n",
              " [array([[0.8001997]], dtype=float32)],\n",
              " [array([[0.6434629]], dtype=float32)],\n",
              " [array([[0.57525235]], dtype=float32)],\n",
              " [array([[0.7193576]], dtype=float32)],\n",
              " [array([[0.04488674]], dtype=float32)],\n",
              " [array([[0.5252346]], dtype=float32)],\n",
              " [array([[0.8543229]], dtype=float32)],\n",
              " [array([[0.8667991]], dtype=float32)],\n",
              " [array([[0.05896807]], dtype=float32)],\n",
              " [array([[0.8997712]], dtype=float32)],\n",
              " [array([[0.642818]], dtype=float32)],\n",
              " [array([[0.66758525]], dtype=float32)],\n",
              " [array([[0.8385718]], dtype=float32)],\n",
              " [array([[0.8667991]], dtype=float32)],\n",
              " [array([[0.8567993]], dtype=float32)],\n",
              " [array([[0.7193576]], dtype=float32)],\n",
              " [array([[0.8543229]], dtype=float32)],\n",
              " [array([[0.71893394]], dtype=float32)],\n",
              " [array([[0.5721027]], dtype=float32)],\n",
              " [array([[0.7103291]], dtype=float32)],\n",
              " [array([[0.83923745]], dtype=float32)],\n",
              " [array([[0.8609761]], dtype=float32)],\n",
              " [array([[0.9351208]], dtype=float32)],\n",
              " [array([[0.90875185]], dtype=float32)],\n",
              " [array([[0.9393333]], dtype=float32)],\n",
              " [array([[0.98271835]], dtype=float32)],\n",
              " [array([[0.8038645]], dtype=float32)],\n",
              " [array([[0.6614133]], dtype=float32)],\n",
              " [array([[0.6811689]], dtype=float32)],\n",
              " [array([[0.58572525]], dtype=float32)],\n",
              " [array([[0.68328196]], dtype=float32)],\n",
              " [array([[0.6383352]], dtype=float32)],\n",
              " [array([[0.9626039]], dtype=float32)],\n",
              " [array([[0.9180148]], dtype=float32)],\n",
              " [array([[0.9702232]], dtype=float32)],\n",
              " [array([[0.6485739]], dtype=float32)],\n",
              " [array([[0.0353308]], dtype=float32)],\n",
              " [array([[0.5623948]], dtype=float32)],\n",
              " [array([[0.7535348]], dtype=float32)],\n",
              " [array([[0.61151063]], dtype=float32)],\n",
              " [array([[0.81411386]], dtype=float32)],\n",
              " [array([[0.64623123]], dtype=float32)],\n",
              " [array([[0.72813904]], dtype=float32)],\n",
              " [array([[0.75433826]], dtype=float32)],\n",
              " [array([[0.5937941]], dtype=float32)],\n",
              " [array([[0.58455837]], dtype=float32)],\n",
              " [array([[0.7168146]], dtype=float32)],\n",
              " [array([[0.47343665]], dtype=float32)],\n",
              " [array([[0.06378657]], dtype=float32)],\n",
              " [array([[0.776242]], dtype=float32)],\n",
              " [array([[0.6103583]], dtype=float32)],\n",
              " [array([[0.55795324]], dtype=float32)],\n",
              " [array([[0.6101563]], dtype=float32)],\n",
              " [array([[0.6081199]], dtype=float32)],\n",
              " [array([[0.59190613]], dtype=float32)],\n",
              " [array([[0.60015064]], dtype=float32)],\n",
              " [array([[0.55063117]], dtype=float32)],\n",
              " [array([[0.8365388]], dtype=float32)],\n",
              " [array([[0.88583624]], dtype=float32)],\n",
              " [array([[0.6711403]], dtype=float32)],\n",
              " [array([[0.5252346]], dtype=float32)],\n",
              " [array([[0.642818]], dtype=float32)],\n",
              " [array([[0.6991304]], dtype=float32)],\n",
              " [array([[0.8356004]], dtype=float32)],\n",
              " [array([[0.76054764]], dtype=float32)],\n",
              " [array([[0.7653924]], dtype=float32)],\n",
              " [array([[0.9811241]], dtype=float32)],\n",
              " [array([[0.9447968]], dtype=float32)],\n",
              " [array([[0.47158507]], dtype=float32)],\n",
              " [array([[0.48005182]], dtype=float32)],\n",
              " [array([[0.48741043]], dtype=float32)],\n",
              " [array([[0.1128301]], dtype=float32)],\n",
              " [array([[0.7420168]], dtype=float32)],\n",
              " [array([[0.00804555]], dtype=float32)],\n",
              " [array([[0.45837787]], dtype=float32)],\n",
              " [array([[0.8416282]], dtype=float32)],\n",
              " [array([[0.00995144]], dtype=float32)],\n",
              " [array([[0.580696]], dtype=float32)],\n",
              " [array([[0.6793456]], dtype=float32)],\n",
              " [array([[0.4389296]], dtype=float32)],\n",
              " [array([[0.00768703]], dtype=float32)],\n",
              " [array([[0.46432734]], dtype=float32)],\n",
              " [array([[0.4512806]], dtype=float32)],\n",
              " [array([[0.4512806]], dtype=float32)],\n",
              " [array([[0.25873682]], dtype=float32)],\n",
              " [array([[0.25608587]], dtype=float32)],\n",
              " [array([[0.3088702]], dtype=float32)],\n",
              " [array([[0.12674987]], dtype=float32)],\n",
              " [array([[0.06850502]], dtype=float32)],\n",
              " [array([[0.22468048]], dtype=float32)],\n",
              " [array([[0.25340667]], dtype=float32)],\n",
              " [array([[0.07355917]], dtype=float32)],\n",
              " [array([[0.6643562]], dtype=float32)],\n",
              " [array([[0.5217604]], dtype=float32)],\n",
              " [array([[0.55599535]], dtype=float32)],\n",
              " [array([[0.1500937]], dtype=float32)],\n",
              " [array([[0.00340986]], dtype=float32)],\n",
              " [array([[0.6977427]], dtype=float32)],\n",
              " [array([[0.5657709]], dtype=float32)],\n",
              " [array([[0.7880537]], dtype=float32)],\n",
              " [array([[0.27584773]], dtype=float32)],\n",
              " [array([[0.56117547]], dtype=float32)],\n",
              " [array([[0.05527249]], dtype=float32)],\n",
              " [array([[0.08220541]], dtype=float32)],\n",
              " [array([[0.70963764]], dtype=float32)],\n",
              " [array([[0.38351816]], dtype=float32)],\n",
              " [array([[0.46866116]], dtype=float32)],\n",
              " [array([[0.05701602]], dtype=float32)],\n",
              " [array([[0.4023288]], dtype=float32)],\n",
              " [array([[0.24246055]], dtype=float32)],\n",
              " [array([[0.5545666]], dtype=float32)],\n",
              " [array([[0.36974743]], dtype=float32)],\n",
              " [array([[0.29757595]], dtype=float32)],\n",
              " [array([[0.21417743]], dtype=float32)],\n",
              " [array([[0.3806784]], dtype=float32)],\n",
              " [array([[0.4679858]], dtype=float32)],\n",
              " [array([[0.5398835]], dtype=float32)],\n",
              " [array([[0.00411761]], dtype=float32)],\n",
              " [array([[0.6017507]], dtype=float32)],\n",
              " [array([[0.02646354]], dtype=float32)],\n",
              " [array([[0.3465539]], dtype=float32)],\n",
              " [array([[0.26213622]], dtype=float32)],\n",
              " [array([[0.7583966]], dtype=float32)],\n",
              " [array([[0.00430232]], dtype=float32)],\n",
              " [array([[0.7841068]], dtype=float32)],\n",
              " [array([[0.53782445]], dtype=float32)],\n",
              " [array([[0.09008458]], dtype=float32)],\n",
              " [array([[0.09008458]], dtype=float32)],\n",
              " [array([[0.02330592]], dtype=float32)],\n",
              " [array([[0.5019608]], dtype=float32)],\n",
              " [array([[0.4830562]], dtype=float32)],\n",
              " [array([[0.08000496]], dtype=float32)],\n",
              " [array([[0.5134782]], dtype=float32)],\n",
              " [array([[0.10675561]], dtype=float32)],\n",
              " [array([[0.21363679]], dtype=float32)],\n",
              " [array([[0.43914664]], dtype=float32)],\n",
              " [array([[0.6590484]], dtype=float32)],\n",
              " [array([[0.70672977]], dtype=float32)],\n",
              " [array([[0.1764332]], dtype=float32)],\n",
              " [array([[0.5398835]], dtype=float32)],\n",
              " [array([[0.35032904]], dtype=float32)],\n",
              " [array([[0.18734866]], dtype=float32)],\n",
              " [array([[0.32548994]], dtype=float32)],\n",
              " [array([[0.1733332]], dtype=float32)],\n",
              " [array([[0.32548994]], dtype=float32)],\n",
              " [array([[0.5111484]], dtype=float32)],\n",
              " [array([[0.42112994]], dtype=float32)],\n",
              " [array([[0.42112994]], dtype=float32)],\n",
              " [array([[0.23313707]], dtype=float32)],\n",
              " [array([[0.38454035]], dtype=float32)],\n",
              " [array([[0.38454035]], dtype=float32)],\n",
              " [array([[0.7333105]], dtype=float32)],\n",
              " [array([[0.50005436]], dtype=float32)],\n",
              " [array([[0.21999276]], dtype=float32)],\n",
              " [array([[0.5697375]], dtype=float32)],\n",
              " [array([[0.72327256]], dtype=float32)],\n",
              " [array([[0.84970367]], dtype=float32)],\n",
              " [array([[0.6931759]], dtype=float32)],\n",
              " [array([[0.9447968]], dtype=float32)],\n",
              " [array([[0.5837761]], dtype=float32)],\n",
              " [array([[0.9447968]], dtype=float32)],\n",
              " [array([[0.8444779]], dtype=float32)],\n",
              " [array([[0.72502166]], dtype=float32)],\n",
              " [array([[0.9359819]], dtype=float32)],\n",
              " [array([[0.8277825]], dtype=float32)],\n",
              " [array([[0.76785076]], dtype=float32)],\n",
              " [array([[0.76919925]], dtype=float32)],\n",
              " [array([[0.0125578]], dtype=float32)],\n",
              " [array([[0.03397578]], dtype=float32)],\n",
              " [array([[0.02622029]], dtype=float32)],\n",
              " [array([[0.03667355]], dtype=float32)],\n",
              " [array([[0.22895235]], dtype=float32)],\n",
              " [array([[0.16456354]], dtype=float32)],\n",
              " [array([[0.2104375]], dtype=float32)],\n",
              " [array([[0.05649722]], dtype=float32)],\n",
              " [array([[0.06500822]], dtype=float32)],\n",
              " [array([[0.00188494]], dtype=float32)],\n",
              " [array([[0.00787616]], dtype=float32)],\n",
              " [array([[0.0412198]], dtype=float32)],\n",
              " [array([[0.1682913]], dtype=float32)],\n",
              " [array([[0.02027121]], dtype=float32)],\n",
              " [array([[0.01845315]], dtype=float32)],\n",
              " [array([[0.00395525]], dtype=float32)],\n",
              " [array([[0.00709784]], dtype=float32)],\n",
              " [array([[0.02787867]], dtype=float32)],\n",
              " [array([[0.05317098]], dtype=float32)],\n",
              " [array([[0.00106964]], dtype=float32)],\n",
              " [array([[0.00060904]], dtype=float32)],\n",
              " [array([[0.01777831]], dtype=float32)],\n",
              " [array([[0.001385]], dtype=float32)],\n",
              " [array([[0.00219664]], dtype=float32)],\n",
              " [array([[0.00166687]], dtype=float32)],\n",
              " [array([[0.00934914]], dtype=float32)],\n",
              " [array([[0.00224796]], dtype=float32)],\n",
              " [array([[0.00217274]], dtype=float32)],\n",
              " [array([[0.00811595]], dtype=float32)],\n",
              " [array([[0.6618648]], dtype=float32)],\n",
              " [array([[0.00700146]], dtype=float32)],\n",
              " [array([[0.51675034]], dtype=float32)],\n",
              " [array([[0.00551844]], dtype=float32)],\n",
              " [array([[0.03151774]], dtype=float32)],\n",
              " [array([[0.15324983]], dtype=float32)],\n",
              " [array([[0.0064207]], dtype=float32)],\n",
              " [array([[0.17462203]], dtype=float32)],\n",
              " [array([[0.13653088]], dtype=float32)],\n",
              " [array([[0.01120254]], dtype=float32)],\n",
              " [array([[0.00826329]], dtype=float32)],\n",
              " [array([[0.12206593]], dtype=float32)],\n",
              " [array([[0.29193762]], dtype=float32)],\n",
              " [array([[0.00426465]], dtype=float32)],\n",
              " [array([[0.00679314]], dtype=float32)],\n",
              " [array([[0.00906751]], dtype=float32)],\n",
              " [array([[0.0062134]], dtype=float32)],\n",
              " [array([[0.00126681]], dtype=float32)],\n",
              " [array([[0.17908287]], dtype=float32)],\n",
              " [array([[0.00516212]], dtype=float32)],\n",
              " [array([[0.04171368]], dtype=float32)],\n",
              " [array([[0.00178808]], dtype=float32)],\n",
              " [array([[0.00100881]], dtype=float32)],\n",
              " [array([[0.00171828]], dtype=float32)],\n",
              " [array([[0.00780702]], dtype=float32)],\n",
              " [array([[0.00208971]], dtype=float32)],\n",
              " [array([[0.13500038]], dtype=float32)],\n",
              " [array([[0.00120309]], dtype=float32)],\n",
              " [array([[0.01121914]], dtype=float32)],\n",
              " [array([[0.00022328]], dtype=float32)],\n",
              " [array([[0.01212439]], dtype=float32)],\n",
              " [array([[0.5567255]], dtype=float32)],\n",
              " [array([[0.46950483]], dtype=float32)],\n",
              " [array([[0.00124151]], dtype=float32)],\n",
              " [array([[0.00278798]], dtype=float32)],\n",
              " [array([[0.01845041]], dtype=float32)],\n",
              " [array([[0.02061847]], dtype=float32)],\n",
              " [array([[0.30915582]], dtype=float32)],\n",
              " [array([[0.00151214]], dtype=float32)],\n",
              " [array([[0.00161034]], dtype=float32)],\n",
              " [array([[0.00124639]], dtype=float32)],\n",
              " [array([[0.05447283]], dtype=float32)],\n",
              " [array([[0.05953383]], dtype=float32)],\n",
              " [array([[0.00072256]], dtype=float32)],\n",
              " [array([[0.05274653]], dtype=float32)],\n",
              " [array([[0.02109325]], dtype=float32)],\n",
              " [array([[0.01023245]], dtype=float32)],\n",
              " [array([[0.15156242]], dtype=float32)],\n",
              " [array([[0.0012868]], dtype=float32)],\n",
              " [array([[0.02046224]], dtype=float32)],\n",
              " [array([[0.01079568]], dtype=float32)],\n",
              " [array([[0.04420555]], dtype=float32)],\n",
              " [array([[0.00091812]], dtype=float32)],\n",
              " [array([[0.05557403]], dtype=float32)],\n",
              " [array([[0.00289947]], dtype=float32)],\n",
              " [array([[0.25725448]], dtype=float32)],\n",
              " [array([[0.0140534]], dtype=float32)],\n",
              " [array([[0.0020856]], dtype=float32)],\n",
              " [array([[0.10258028]], dtype=float32)],\n",
              " [array([[0.00100237]], dtype=float32)],\n",
              " [array([[0.00080016]], dtype=float32)],\n",
              " [array([[0.0026426]], dtype=float32)],\n",
              " [array([[0.01661354]], dtype=float32)],\n",
              " [array([[0.00737333]], dtype=float32)],\n",
              " [array([[0.00176445]], dtype=float32)],\n",
              " [array([[0.00809172]], dtype=float32)],\n",
              " [array([[0.08315024]], dtype=float32)],\n",
              " [array([[0.00572148]], dtype=float32)],\n",
              " [array([[0.40599102]], dtype=float32)],\n",
              " [array([[0.0010232]], dtype=float32)],\n",
              " [array([[0.03530815]], dtype=float32)],\n",
              " [array([[0.00451159]], dtype=float32)],\n",
              " [array([[0.00053763]], dtype=float32)],\n",
              " [array([[0.16828701]], dtype=float32)],\n",
              " [array([[0.00276762]], dtype=float32)],\n",
              " [array([[0.00821263]], dtype=float32)],\n",
              " [array([[0.00842962]], dtype=float32)],\n",
              " [array([[0.05500075]], dtype=float32)],\n",
              " [array([[0.00955895]], dtype=float32)],\n",
              " [array([[0.0131956]], dtype=float32)],\n",
              " [array([[0.00501153]], dtype=float32)],\n",
              " [array([[0.00120869]], dtype=float32)],\n",
              " [array([[0.00466883]], dtype=float32)],\n",
              " [array([[0.1493122]], dtype=float32)],\n",
              " [array([[0.12729356]], dtype=float32)],\n",
              " [array([[0.06154275]], dtype=float32)],\n",
              " [array([[0.00404423]], dtype=float32)],\n",
              " [array([[0.00238845]], dtype=float32)],\n",
              " [array([[0.23976201]], dtype=float32)],\n",
              " [array([[0.00277933]], dtype=float32)],\n",
              " [array([[0.04965207]], dtype=float32)],\n",
              " [array([[0.00567845]], dtype=float32)],\n",
              " [array([[0.04197115]], dtype=float32)],\n",
              " [array([[0.00208837]], dtype=float32)],\n",
              " [array([[0.00385907]], dtype=float32)],\n",
              " [array([[0.00100583]], dtype=float32)],\n",
              " [array([[0.00219464]], dtype=float32)],\n",
              " [array([[0.00201657]], dtype=float32)],\n",
              " [array([[0.25710115]], dtype=float32)],\n",
              " [array([[0.9917736]], dtype=float32)],\n",
              " [array([[0.9514066]], dtype=float32)],\n",
              " [array([[0.00446203]], dtype=float32)],\n",
              " [array([[0.66179144]], dtype=float32)],\n",
              " [array([[0.4531052]], dtype=float32)],\n",
              " [array([[0.75648975]], dtype=float32)],\n",
              " [array([[0.60947543]], dtype=float32)],\n",
              " [array([[0.6885569]], dtype=float32)],\n",
              " [array([[0.6736039]], dtype=float32)],\n",
              " [array([[0.5103361]], dtype=float32)],\n",
              " [array([[0.6030599]], dtype=float32)],\n",
              " [array([[0.6583003]], dtype=float32)],\n",
              " [array([[0.15219656]], dtype=float32)],\n",
              " [array([[0.3313648]], dtype=float32)],\n",
              " [array([[0.31743252]], dtype=float32)],\n",
              " [array([[0.47778222]], dtype=float32)],\n",
              " [array([[0.5011093]], dtype=float32)],\n",
              " [array([[0.35984117]], dtype=float32)],\n",
              " [array([[0.7293837]], dtype=float32)],\n",
              " [array([[0.4644656]], dtype=float32)],\n",
              " [array([[0.6080445]], dtype=float32)],\n",
              " [array([[0.6692016]], dtype=float32)],\n",
              " [array([[0.6468901]], dtype=float32)],\n",
              " [array([[0.7138169]], dtype=float32)],\n",
              " [array([[0.7138169]], dtype=float32)],\n",
              " [array([[0.4375162]], dtype=float32)],\n",
              " [array([[0.8925995]], dtype=float32)],\n",
              " [array([[0.75028557]], dtype=float32)],\n",
              " [array([[0.9473329]], dtype=float32)],\n",
              " [array([[0.7475942]], dtype=float32)],\n",
              " [array([[0.7800944]], dtype=float32)],\n",
              " [array([[0.39962074]], dtype=float32)],\n",
              " [array([[0.09311488]], dtype=float32)],\n",
              " [array([[0.28997916]], dtype=float32)],\n",
              " [array([[0.65451396]], dtype=float32)],\n",
              " [array([[0.2880373]], dtype=float32)],\n",
              " [array([[0.5089448]], dtype=float32)],\n",
              " [array([[0.42864442]], dtype=float32)],\n",
              " [array([[0.4551601]], dtype=float32)],\n",
              " [array([[0.45255858]], dtype=float32)],\n",
              " [array([[0.69395995]], dtype=float32)],\n",
              " [array([[0.8068343]], dtype=float32)],\n",
              " [array([[0.7509241]], dtype=float32)],\n",
              " [array([[0.66530174]], dtype=float32)],\n",
              " [array([[0.3301813]], dtype=float32)],\n",
              " [array([[0.05290306]], dtype=float32)],\n",
              " [array([[0.01793805]], dtype=float32)],\n",
              " [array([[0.11037552]], dtype=float32)],\n",
              " [array([[0.06188554]], dtype=float32)],\n",
              " [array([[0.00732091]], dtype=float32)],\n",
              " [array([[0.03063619]], dtype=float32)],\n",
              " [array([[0.7519701]], dtype=float32)],\n",
              " [array([[0.8877212]], dtype=float32)],\n",
              " [array([[0.4597723]], dtype=float32)],\n",
              " [array([[0.04673791]], dtype=float32)],\n",
              " [array([[0.06340113]], dtype=float32)],\n",
              " [array([[0.18043333]], dtype=float32)],\n",
              " [array([[0.10367614]], dtype=float32)],\n",
              " [array([[0.37405103]], dtype=float32)],\n",
              " [array([[0.01945788]], dtype=float32)],\n",
              " [array([[0.17389858]], dtype=float32)],\n",
              " [array([[0.05154115]], dtype=float32)]]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for input_dict in encoded_pair:\n",
        "    input_dict_np={input_ids:input_dict[0][0],attention_mask:input_dict[0][1], token_type_ids:input_dict[0][2]}\n",
        "    onnx_results = sess.run(None,input_dict_np)\n",
        "    final_result.append(onnx_results)\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3mkd7Pgji-y"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "providers = [\n",
        "    ('TensorrtExecutionProvider', {\n",
        "        'device_id': 1,\n",
        "        'trt_max_workspace_size': 2147483648,\n",
        "        'trt_fp16_enable': True,\n",
        "    }),\n",
        "    ('CUDAExecutionProvider', {\n",
        "        'device_id': 1,\n",
        "        'arena_extend_strategy': 'kNextPowerOfTwo',\n",
        "        'gpu_mem_limit': 2 * 1024 * 1024 * 1024,\n",
        "        'cudnn_conv_algo_search': 'EXHAUSTIVE',\n",
        "        'do_copy_in_default_stream': True,\n",
        "    })\n",
        "]\n",
        "\n",
        "sess_opt = ort.SessionOptions()\n",
        "sess = ort.InferenceSession('bert.onnx', sess_options=sess_opt, providers=providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3PwiAczlG1G"
      },
      "outputs": [],
      "source": [
        "for input_dict in encoded_pair:\n",
        "    input_dict_np={input_ids:input_dict[0][0],attention_mask:input_dict[0][1], token_type_ids:input_dict[0][2]}\n",
        "    onnx_results = sess.run(None,input_dict_np)\n",
        "    final_result.append(onnx_results)\n",
        "\n",
        "final_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3LNADesfzxB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}