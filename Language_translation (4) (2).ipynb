{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af11e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip jigsaw-unintended-bias-train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba701c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24345d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e0b4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language_supported=['ar_AR', 'de_DE', 'en_XX', 'es_XX', 'fi_FI', 'fr_XX', 'hi_IN', 'it_IT', 'ja_XX', 'ko_KR']\n",
    "                    \n",
    "#language_supported=['nl_XX', 'ro_RO', 'ru_RU', 'tr_TR', 'vi_VN', 'zh_CN', 'bn_IN', 'he_IL', 'hr_HR', 'id_ID']\n",
    "                    \n",
    "language_supported=['tl_XX','uk_UA']\n",
    "\n",
    "## , 'ur_PK'\n",
    "\n",
    "len(language_supported)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a40bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxicity', 'obscene',\n",
       "       'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
       "       'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu',\n",
       "       'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability',\n",
       "       'jewish', 'latino', 'male', 'muslim', 'other_disability',\n",
       "       'other_gender', 'other_race_or_ethnicity', 'other_religion',\n",
       "       'other_sexual_orientation', 'physical_disability',\n",
       "       'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date',\n",
       "       'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow',\n",
       "       'sad', 'likes', 'disagree', 'sexual_explicit',\n",
       "       'identity_annotator_count', 'toxicity_annotator_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df=pd.read_csv(\"jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2746b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c57a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df[\"rating\"]==\"approved\"]\n",
    "df=df[['id','comment_text', 'toxic', 'severe_toxicity', 'obscene',\n",
    "       'identity_attack', 'insult', 'threat', 'sexual_explicit', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6d1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"length\"]=df['comment_text'].apply(lambda x: len(x.split()))\n",
    "df=df[df[\"length\"]<=20]\n",
    "df = df.drop_duplicates(subset=['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2686021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "import torch\n",
    "\n",
    "# Check if a GPU is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\").to(device)\n",
    "\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb11e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec 17 06:25:33 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   29C    P0              30W /  70W |   2445MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     23475      C   ...conda3/envs/pytorch_p310/bin/python     2442MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06547406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tl_XX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# Set the source language (assuming it's English)\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 20\n",
    "\n",
    "for lang in language_supported:\n",
    "    print(lang)\n",
    "    \n",
    "    # Create an empty DataFrame for the translated data\n",
    "    translated_data_list = []\n",
    "    sampled_dataframe = df.sample(n=150000, random_state=42)  # You can use any random_state value for reproducibility\n",
    "\n",
    "    # Iterate over batches of input sentences\n",
    "    for batch_start in range(0, len(sampled_dataframe), batch_size):\n",
    "        batch_end = batch_start + batch_size\n",
    "        batch_comments = sampled_dataframe['comment_text'].iloc[batch_start:batch_end].tolist()\n",
    "\n",
    "        # Encode the batch\n",
    "        encoded_batch = tokenizer(batch_comments, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        \n",
    "        # Generate translations\n",
    "        generated_tokens = model.generate(\n",
    "            **encoded_batch,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[lang],\n",
    "            max_length=256  # Adjust this based on your maximum sequence length\n",
    "        )\n",
    "        \n",
    "        # Decode and collect translated texts\n",
    "        translated_texts = tokenizer.batch_decode(generated_tokens.cpu(), skip_special_tokens=True)\n",
    "        \n",
    "        # Create a DataFrame for the batch\n",
    "        batch_data = [{\"id\": sampled_dataframe['id'].iloc[batch_start + index], f'comment_text_{lang}': text}\n",
    "                      for index, text in enumerate(translated_texts)]\n",
    "        \n",
    "        # Append the batch data to the translated_data_list\n",
    "        translated_data_list.extend(batch_data)\n",
    "    \n",
    "    # Create a DataFrame for all translated data\n",
    "    df_new = pd.DataFrame(translated_data_list)\n",
    "    \n",
    "    # Save the translated data to a CSV file\n",
    "    df_new.to_csv(f\"translated_data_{lang}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01602d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178129d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(translated_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang=\"ta_IN\"\n",
    "# Create a DataFrame for all translated data\n",
    "df_new = pd.DataFrame(translated_data_list)\n",
    "\n",
    "# Save the translated data to a CSV file\n",
    "df_new.to_csv(f\"translated_data_{lang}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482faab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da27b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
